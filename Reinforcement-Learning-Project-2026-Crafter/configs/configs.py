"""
FIXED configuration file with corrected hyperparameters

KEY FIXES:
- Improvement 1: Learning rate 1e-4 (was 2.5e-4 - too high!)
- Improvement 2: Conservative exploration (was too aggressive)
- Both: Match baseline's proven settings with minimal changes
"""

# ============================================================================
# DQN BASELINE CONFIGURATION
# ============================================================================
DQN_CONFIG = {
    'name': 'DQN_Baseline_GTX750Ti',
    'total_timesteps': 500000,
    'eval_freq': 10000,
    'save_freq': 50000,
    
    'learning_rate': 1e-4,
    'buffer_size': 50000,
    'learning_starts': 5000,
    'batch_size': 32,
    'gamma': 0.99,
    'target_update_interval': 5000,
    'train_freq': 4,
    'gradient_steps': 1,
    
    'exploration_fraction': 0.15,
    'exploration_initial_eps': 1.0,
    'exploration_final_eps': 0.05,
    
    'preprocess_type': 'none',
    'reward_shaping': 'none',
    
    'device': 'cuda',
    'seed': 42,
}

# ============================================================================
# IMPROVEMENT 1: Simplified CNN Enhancement (FIXED + MEMORY OPTIMIZED)
# ============================================================================
# CHANGES FROM BASELINE:
# 1. Observation normalization (0-255 â†’ 0-1)
# 2. Slightly wider CNN (48-96-96 vs 32-64-64)  
# 3. Better weight initialization
# 4. MEMORY OPTIMIZED: 75k buffer (fits GTX 750 Ti)
# 5. ALL OTHER HYPERPARAMETERS SAME AS BASELINE!
# ============================================================================
DQN_IMPROVEMENT_1 = {
    'name': 'DQN_Improvement1_Simplified',
    'total_timesteps': 500000,
    'eval_freq': 10000,
    'save_freq': 50000,
    
    # Memory settings - OPTIMIZED FOR GTX 750 Ti
    'batch_size': 32,              # SAME as baseline
    'buffer_size': 75000,          # REDUCED to fit 2GB (was 100k)
    'learning_starts': 10000,      # More samples before training
    
    # Learning rate - CRITICAL FIX
    'learning_rate': 1e-4,         # FIXED: Same as baseline (was 2.5e-4)
    'gamma': 0.99,                 # SAME as baseline
    'target_update_interval': 10000,  # SAME as baseline  
    'train_freq': 4,               # SAME as baseline
    'gradient_steps': 1,           # SAME as baseline
    
    # Exploration - SAME as baseline
    'exploration_fraction': 0.1,   # FIXED: Same as baseline (was 0.2)
    'exploration_initial_eps': 1.0,
    'exploration_final_eps': 0.05,
    
    # Improvements
    'preprocess_type': 'normalize',  # KEY IMPROVEMENT
    'reward_shaping': 'none',        # No reward shaping
    'use_custom_cnn': True,          # Simplified CNN
    'use_frame_stacking': False,
    
    'device': 'cuda',
    'seed': 42,
}

# ============================================================================
# IMPROVEMENT 2: Curriculum Learning (FINAL FIX)
# ============================================================================
# CHANGES FROM IMPROVEMENT 1:
# 1. Extended exploration (30% vs 10%) - more time to discover achievements
# 2. Larger replay buffer (100k vs 75k) - more experience diversity
# 3. Lower final epsilon (0.01 vs 0.05) - better exploitation once learned
# 4. NO reward shaping - keeps training/eval consistent
# 5. Same proven CNN architecture as Improvement 1
# ============================================================================
DQN_IMPROVEMENT_2 = {
    'name': 'DQN_Improvement2_FrameStack',
    'total_timesteps': 500000,
    'eval_freq': 10000,
    'save_freq': 50000,
    
    # Memory settings - SAME as Improvement 1
    'batch_size': 32,
    'buffer_size': 25000,          # SAME as Improv1
    'learning_starts': 10000,      # SAME as Improv1
    
    # Learning - SAME as Improvement 1
    'learning_rate': 1e-4,
    'gamma': 0.99,
    'target_update_interval': 10000,
    'train_freq': 4,
    'gradient_steps': 1,
    
    # Exploration - SAME as Improvement 1
    'exploration_fraction': 0.1,   # SAME as Improv1
    'exploration_initial_eps': 1.0,
    'exploration_final_eps': 0.05, # SAME as Improv1
    
    # Key improvement: Frame stacking
    'preprocess_type': 'normalize',
    'reward_shaping': 'none',
    'use_custom_cnn': True,
    'n_stack': 4,                  # NEW: Stack 4 frames
    'use_frame_stacking': True,    # NEW: Enable frame stacking
    
    'device': 'cuda',
    'seed': 42,
}

DQN_IMPROVEMENT_3 = {
    'name': 'DQN_Improvement3_LSTM',
    'total_timesteps': 500000,
    'eval_freq': 10000,
    'save_freq': 50000,
    
    # Memory settings - SAME as Improvement 1
    'batch_size': 32,
    'buffer_size': 25000,          # SAME as Improv1
    'learning_starts': 10000,      # SAME as Improv1
    
    # Learning - SAME as Improvement 1
    'learning_rate': 1e-4,
    'gamma': 0.99,
    'target_update_interval': 10000,
    'train_freq': 4,
    'gradient_steps': 1,
    
    # Exploration - SAME as Improvement 1
    'exploration_fraction': 0.1,   # SAME as Improv1
    'exploration_initial_eps': 1.0,
    'exploration_final_eps': 0.05, # SAME as Improv1
    
    # Key improvement: Frame stacking
    'preprocess_type': 'normalize',
    'reward_shaping': 'none',
    'use_custom_cnn': True,
    'n_stack': 4,                  # NEW: Stack 4 frames
    'use_frame_stacking': True,    # NEW: Enable frame stacking
    
    'device': 'cuda',
    'seed': 42,
}

# ============================================================================
# QUICK TEST CONFIGURATION
# ============================================================================
QUICK_TEST_CONFIG = {
    'name': 'DQN_QuickTest',
    'total_timesteps': 10000,
    'eval_freq': 2000,
    'buffer_size': 10000,
    'learning_starts': 1000,
    'batch_size': 32,
    'learning_rate': 1e-4,
    'gamma': 0.99,
    'target_update_interval': 1000,
    'train_freq': 4,
    'gradient_steps': 1,
    'exploration_fraction': 0.15,
    'exploration_initial_eps': 1.0,
    'exploration_final_eps': 0.05,
    'preprocess_type': 'none',
    'reward_shaping': 'none',
    'device': 'cuda',
    'seed': 42,
}

# ============================================================================
# UTILITY FUNCTIONS
# ============================================================================

def get_config(config_name='DQN_CONFIG'):
    """Get configuration by name"""
    configs = {
        'DQN_CONFIG': DQN_CONFIG,
        'DQN_IMPROVEMENT_1': DQN_IMPROVEMENT_1,
        'DQN_IMPROVEMENT_2': DQN_IMPROVEMENT_2,
        'DQN_IMPROVEMENT_3': DQN_IMPROVEMENT_3,
        'QUICK_TEST_CONFIG': QUICK_TEST_CONFIG,
    }
    
    if config_name not in configs:
        raise ValueError(f"Unknown config: {config_name}. Available: {list(configs.keys())}")
    
    return configs[config_name].copy()


def print_config(config):
    """Print configuration"""
    print("\n" + "="*70)
    print(f"CONFIGURATION: {config.get('name', 'Unnamed')}")
    print("="*70)
    
    groups = {
        'Training': ['total_timesteps', 'eval_freq', 'learning_rate'],
        'Memory': ['buffer_size', 'batch_size', 'learning_starts'],
        'Exploration': ['exploration_fraction', 'exploration_initial_eps', 'exploration_final_eps'],
        'Environment': ['preprocess_type', 'reward_shaping'],
        'Hardware': ['device', 'seed'],
    }
    
    for group_name, keys in groups.items():
        print(f"\n{group_name}:")
        for key in keys:
            if key in config:
                print(f"  {key:30s}: {config[key]}")
    
    printed_keys = set()
    for keys in groups.values():
        printed_keys.update(keys)
    printed_keys.add('name')
    
    remaining = {k: v for k, v in config.items() if k not in printed_keys}
    if remaining:
        print("\nOther Parameters:")
        for key, value in remaining.items():
            print(f"  {key:30s}: {value}")
    
    print("="*70 + "\n")


def estimate_memory_usage(config):
    """Estimate GPU memory usage"""
    obs_size_mb = 64 * 64 * 3 / 1024 / 1024
    buffer_memory = config['buffer_size'] * obs_size_mb * 2
    batch_memory = config['batch_size'] * obs_size_mb * 4
    model_memory = 50
    total_mb = buffer_memory + batch_memory + model_memory
    total_gb = total_mb / 1024
    return total_gb